# -*- coding: utf-8 -*-
"""Resnet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OKDcAr5kBqqEeE9P1lLiWlUEBqd1TWLB
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import PIL
import cv2
import uuid
import shutil
import random
import glob as gb
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline

from PIL import Image
from tqdm import tqdm  # Progress bar
from scipy.special import gamma

from keras.optimizers import *
from keras.regularizers import l1_l2
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Input
from keras.layers import GlobalAveragePooling2D
from keras.callbacks import LearningRateScheduler
from keras.layers import Conv2D, MaxPool2D, BatchNormalization

from tensorflow.keras.metrics import *
from tensorflow.keras.callbacks import *
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import shutil

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import load_model
import numpy as np
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import load_model
import cv2
from tensorflow.keras.applications import ResNet50
model_directory = "/content/drive/MyDrive/ Breastcancer_Project1/working/save_model/"

from google.colab import drive
drive.mount('/content/drive')

"""#c"""

# import os
# for dirname, _, filenames in os.walk('/content/drive/MyDrive/dataset'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

# def replace_path(sample, old_path, new_path):
#     return sample.replace(old_path, new_path, regex=True)

# def plot_smaples(sample, row=15, col=15):
#     plt.figure(figsize=(row, col))
#     for i, file in enumerate(sample[0:5]):
#         cropped_images_show = PIL.Image.open(file)
#         gray_img= cropped_images_show.convert("L")
#         plt.subplot(1,5,i+1)
#         plt.imshow(gray_img, cmap='gray')
#         plt.axis('off')
#     plt.show()

# calc_train = pd.read_csv('/content/drive/MyDrive/dataset/csv/calc_case_description_train_set.csv')
# calc_test = pd.read_csv('/content/drive/MyDrive/dataset/csv/calc_case_description_test_set.csv')
# mass_train = pd.read_csv('/content/drive/MyDrive/dataset/csv/mass_case_description_train_set.csv')
# mass_test = pd.read_csv('/content/drive/MyDrive/dataset/csv/mass_case_description_test_set.csv')
# dicom_df = pd.read_csv('/content/drive/MyDrive/dataset/csv/dicom_info.csv')

# cropped_images = dicom_df[dicom_df.SeriesDescription=="cropped images"].image_path
# full_mammogram = dicom_df[dicom_df.SeriesDescription=="full mammogram images"].image_path
# roi_mask = dicom_df[dicom_df.SeriesDescription=="ROI mask images"].image_path

# # Replace the path for cropped_images to the correct directory.
# correct_dir = "/content/drive/MyDrive/dataset/jpeg"
# cropped_images = replace_path(cropped_images, "CBIS-DDSM/jpeg", correct_dir)
# print('Cropped Images paths:')
# print(cropped_images.iloc[0]) # Print to ensure everything looks correct.

# cropped_images[0]

# import cv2
# img=cv2.imread("/content/drive/MyDrive/dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.129308726812851964007517874181459556304/1-172.jpg")
# img.shape

# plt.imshow(img)

# # Replace the path for full_mammogram images to the correct directory.
# full_mammogram = replace_path(full_mammogram, "CBIS-DDSM/jpeg", correct_dir)
# print('\nFull mammo Images paths:')
# print(full_mammogram.iloc[0]) # Print to ensure everything looks correct.

# full_mammogram

# # Replace the path for roi_mask images to the correct directory.
# roi_mask = replace_path(roi_mask, "CBIS-DDSM/jpeg", correct_dir)
# print('\nROI Mask Images paths:')
# print(roi_mask.iloc[0]) # Print to ensure everything looks correct.

# roi_mask[5]

# def get_image_file_name(data, new_dict):

#     for dicom in data:
#         print(dicom)
#         key = dicom.split('/')[6]
#         print(key)
#         new_dict[key] = dicom
#     print(f"the length of dataset ==> {len(new_dict.keys())}")

# for dicom in cropped_images:
#         print(dicom)
#         key = dicom.split('/')[6]
#         print(key)

# cropped_images_dict = dict()
# full_mammo_dict = dict()
# roi_img_dict = dict()

# get_image_file_name(cropped_images, cropped_images_dict)
# get_image_file_name(full_mammogram, full_mammo_dict)
# get_image_file_name(roi_mask, roi_img_dict)

# def fix_image_path(data):
#     """Correct dicom paths to correct image paths."""
#     for indx, image in enumerate(data.values):

#         img_name = image[11].split('/')[2]

#         if img_name in full_mammo_dict:
#             data.iloc[indx, 11] = full_mammo_dict[img_name]
#         else:
#             data.iloc[indx, 11] = None

#         img_name = image[12].split('/')[2]
#         if img_name in cropped_images_dict:
#             data.iloc[indx, 12] = cropped_images_dict[img_name]
#         else:
#             data.iloc[indx, 11] = None

#         img_name = image[13].split('/')[2]
#         if img_name in roi_img_dict:
#             data.iloc[indx, 13] = roi_img_dict[img_name]

#         else:
#             data.iloc[indx, 13] = None


#     print(data)

# fix_image_path(mass_train)

# mass_train = mass_train.rename(columns={'left or right breast': 'left_or_right_breast',
#                                         'image view': 'image_view',
#                                         'abnormality id': 'abnormality_id',
#                                         'abnormality type': 'abnormality_type',
#                                         'mass shape': 'mass_shape',
#                                         'mass margins': 'mass_margins',
#                                         'image file path': 'image_file_path',
#                                         'cropped image file path': 'cropped_image_file_path',
#                                         'ROI mask file path': 'ROI_mask_file_path'})
# mass_train.head(5)

# mass_train.pathology.unique()

# fix_image_path(mass_test)

# mass_test = mass_test.rename(columns={'left or right breast': 'left_or_right_breast',
#                                       'image view': 'image_view',
#                                       'abnormality id': 'abnormality_id',
#                                       'abnormality type': 'abnormality_type',
#                                       'mass shape': 'mass_shape',
#                                       'mass margins': 'mass_margins',
#                                       'image file path': 'image_file_path',
#                                       'cropped image file path': 'cropped_image_file_path',
#                                       'ROI mask file path': 'ROI_mask_file_path'})
# # view renamed columns
# mass_test.head()

# calc_train = calc_train.rename(columns={'left or right breast': 'left_or_right_breast',
#                                         'image view': 'image_view',
#                                         'abnormality id': 'abnormality_id',
#                                         'abnormality type': 'abnormality_type',
#                                         'mass shape': 'mass_shape',
#                                         'mass margins': 'mass_margins',
#                                         'image file path': 'image_file_path',
#                                         'cropped image file path': 'cropped_image_file_path',
#                                         'ROI mask file path': 'ROI_mask_file_path'})
# # view renamed columns
# calc_train.head()

# fix_image_path(calc_train)

# calc_test = calc_test.rename(columns={'left or right breast': 'left_or_right_breast',
#                                       'image view': 'image_view',
#                                       'abnormality id': 'abnormality_id',
#                                       'abnormality type': 'abnormality_type',
#                                       'mass shape': 'mass_shape',
#                                       'mass margins': 'mass_margins',
#                                       'image file path': 'image_file_path',
#                                       'cropped image file path': 'cropped_image_file_path',
#                                       'ROI mask file path': 'ROI_mask_file_path'})
# # view renamed columns
# calc_test.head()

# calc_test

# fix_image_path(calc_test)

# def display_images(dataset, column, number):
#     """Displays images in dataset, handling missing files and converting formats."""

#     # create figure and axes
#     fig, axes = plt.subplots(1, number, figsize=(15, 5))

#     # Loop through rows and display images
#     for index, (i, row) in enumerate(dataset.head(number).iterrows()):
#         image_path = row[column]

#        # Check if image_path is valid (not None) and exists
#         if image_path is None or not os.path.exists(image_path):
#             # print(f"File not found or invalid path: {image_path}")
#             continue

#         image = cv2.imread(image_path)

#         # Handle case when image can't be read
#         if image is None:
#             # print(f"Error reading image: {image_path}")
#             continue

#         # Convert BGR to RGB if needed (for correct color display)
#         if len(image.shape) == 3 and image.shape[2] == 3:
#             image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

#         ax = axes[index]
#         ax.imshow(image, cmap='gray' if len(image.shape) == 2 else None)
#         ax.set_title(f"{row['pathology']}")
#         ax.axis('off')
#         print(np.array(image).shape)

#     plt.tight_layout()
#     plt.show()

# mass_train['image_file_path']

# print('Full Mammograms:\n')
# display_images(mass_train, 'image_file_path', 5)
# print('Cropped Mammograms:\n')
# display_images(mass_train, 'cropped_image_file_path', 5)
# print('ROI_mask:\n')
# display_images(mass_train, 'ROI_mask_file_path', 5)

# print('Full Mammograms:\n')
# display_images(mass_test, 'image_file_path', 5)
# print('Cropped Mammograms:\n')
# display_images(mass_test, 'cropped_image_file_path', 5)
# print('ROI_mask:\n')
# display_images(mass_test, 'ROI_mask_file_path', 5)

# print('Full Mammograms:\n')
# display_images(calc_train, 'image_file_path', 5)
# print('Cropped Mammograms:\n')
# display_images(calc_train, 'cropped_image_file_path', 5)
# print('ROI_mask:\n')
# display_images(calc_train, 'ROI_mask_file_path', 5)

# print('Full Mammograms:\n')
# display_images(calc_test, 'image_file_path', 5)
# print('Cropped Mammograms:\n')
# display_images(calc_test, 'cropped_image_file_path', 5)
# print('ROI_mask:\n')
# display_images(calc_test, 'ROI_mask_file_path', 5)

# full_dataset = pd.concat([calc_train, calc_test], axis=0)

# len(full_dataset)

# full_dataset

# class_mapper = {'MALIGNANT': 1, 'BENIGN': 0, 'BENIGN_WITHOUT_CALLBACK': 0}

# target_size = (224, 224, 3)

# # Apply class mapper to pathology column
# full_dataset['labels'] = full_dataset['pathology'].replace(class_mapper).infer_objects(copy=False)

# full_images = np.array(full_dataset[full_dataset["image_file_path"].notna()]["image_file_path"].tolist())
# full_labels = np.array(full_dataset[full_dataset["image_file_path"].notna()]["labels"].tolist())

# len(full_images)

# # If full_labels is a NumPy array, convert it to a Pandas series
# full_labels_series = pd.Series(full_labels)

# # Count the occurrences of each class
# label_counts = full_labels_series.value_counts()

# # Assuming 0 = benign and 1 = malignant
# benign_count = label_counts.get(0, 0)
# malignant_count = label_counts.get(1, 0)

# print(f"Benign images: {benign_count}")
# print(f"Malignant images: {malignant_count}")

# num_classes = len(full_dataset['labels'].unique())
# num_classes

# class_names = ['Benign', 'Malignant']

# # Check the distribution of labels
# label_counts = full_dataset['labels'].value_counts()
# print(label_counts)

# full_dataset

# # Define a function for data augmentation
# def augment_image(image):

#     #return image


#     # Apply data augmentation using tf.image functions
#     image = tf.image.random_flip_left_right(image)
#     #     image = tf.image.random_flip_up_down(image)
#     image = tf.image.random_brightness(image, max_delta=0.3)
#     image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
#     image = tf.image.random_saturation(image, lower=0.8, upper=1.2)
#     return image


# # Function to resize image to (224, 224, 3)
# def resize_image(image_tensor):
#     return tf.image.resize(image_tensor, [224, 224])

# # Function to balance classes by augmenting images
# def copy_images_with_unique_filenames(images, labels, source, destination, target_count=None):
#     """
#     Copy images from source to destination in subfolders '0' and '1',
#     ensuring unique filenames and applying data augmentation and balancing.
#     """
#     benign_images = 0
#     malignant_images = 0
#     skipped_images = []

#     if os.path.exists(os.path.join(destination, '0')) and os.path.isdir(os.path.join(destination, '0')):
#         # Delete the folder and its contents
#         shutil.rmtree(os.path.join(destination, '0'))
#         print(f"Folder '{os.path.join(destination, '0')}' has been deleted.")

#     if os.path.exists(os.path.join(destination, '1')) and os.path.isdir(os.path.join(destination, '1')):
#         # Delete the folder and its contents
#         shutil.rmtree(os.path.join(destination, '1'))
#         print(f"Folder '{os.path.join(destination, '1')}' has been deleted.")

#     # Create the destination subfolders '0' and '1'
#     category_dest_dir_zero = os.path.join(destination, '0')
#     os.makedirs(category_dest_dir_zero, exist_ok=True)

#     category_dest_dir_one = os.path.join(destination, '1')
#     os.makedirs(category_dest_dir_one, exist_ok=True)

#     benign_images_list = []
#     malignant_images_list = []

#     for i, (image, label) in enumerate(zip(images, labels)):
# #         img_name = data_frame.REFNUM[i]
# #         abs_path = os.path.join(source, img_name + '.pgm')

#         if os.path.exists(image):
#             try:
#                 # Generate a unique filename
#                 filename = os.path.basename(image)
#                 unique_filename = f"{uuid.uuid4().hex}_{filename}"

#                 # Open the image using PIL
#                 with Image.open(image) as img:
#                     # Convert the image to RGB mode (for saving as JPEG)
#                     img = img.convert('RGB')
#                     # Augment the image (convert it to a Tensor first)
#                     img_tensor = tf.convert_to_tensor(img)
#                     # Resize the image to (224, 224, 3)
#                     resized_img_tensor = resize_image(img_tensor)
#                     augmented_image_tensor = augment_image(resized_img_tensor)
#                     # Convert Tensor back to PIL image for saving
#                     augmented_image = tf.keras.preprocessing.image.array_to_img(augmented_image_tensor)

#                     if label == 0:
#                         benign_images_list.append(unique_filename)
#                         dest_path = os.path.join(category_dest_dir_zero, unique_filename)
# #                         augmented_image.save(dest_path, 'JPEG')
#                         augmented_image.save(dest_path, 'JPEG')
#                         benign_images += 1

#                     elif label == 1:
#                         malignant_images_list.append(unique_filename)
#                         dest_path = os.path.join(category_dest_dir_one, unique_filename)
# #                         augmented_image.save(dest_path, 'JPEG')
#                         augmented_image.save(dest_path, 'JPEG')
#                         malignant_images += 1

# #                 del img, img_tensor, resized_img_tensor, augmented_image_tensor, augmented_image
# #                 gc.collect()
#             except Exception as e:
#                 print(f"Error copying image {image}: {e}")
#                 skipped_images.append(image)
#         else:
#             print(f"Image not found: {image}")
#             skipped_images.append(image)

#     # If balancing is needed, duplicate/augment images from the smaller class
#     benign_count = len(benign_images_list)
#     malignant_count = len(malignant_images_list)

#     if benign_count < malignant_count:
# #         augment_and_save_images(benign_images_list, category_dest_dir_zero, target_count - benign_count)
#         augment_and_save_images(benign_images_list, category_dest_dir_zero, malignant_count - benign_count)

#     elif malignant_count < benign_count:
#         augment_and_save_images(malignant_images_list, category_dest_dir_one, benign_count - malignant_count)

#     augment_and_save_images(benign_images_list, category_dest_dir_zero, target_count)
#     augment_and_save_images(malignant_images_list, category_dest_dir_one, target_count)

#     print(f"\nCopying complete.")
#     print(f"Benign images copied (label 0): {benign_images}")
#     print(f"Benign count (label 0): {benign_count}")
#     print(f"Malignant images copied (label 1): {malignant_images}")
#     print(f"Malignant count (label 1): {malignant_count}")
#     print(f"Total skipped images: {len(skipped_images)}")
#     if skipped_images:
#         print("Skipped images:")
#         for img in skipped_images:
#             print(img)


# # Function to augment and save images to balance the dataset
# def augment_and_save_images(images_list, destination_dir, num_augments):
#     """
#     Augment and save images to balance the dataset.
#     """
#     for i in range(num_augments):
#         img_name = random.choice(images_list)
#         abs_path = os.path.join(destination_dir, img_name)

#         try:
#             with Image.open(abs_path) as img:
#                 img = img.convert('RGB')
#                 # Augment the image
#                 img_tensor = tf.convert_to_tensor(img)
#                 # Resize the image
# #                 resized_img_tensor = resize_image(img_tensor)
#                 augmented_image_tensor = augment_image(img_tensor)
#                 # Convert Tensor back to PIL image for saving
#                 augmented_image = tf.keras.preprocessing.image.array_to_img(augmented_image_tensor)
#                 # Remove the original extension from img_name 1-285.jpg --> 1-285
#                 img_name_without_ext = os.path.splitext(img_name)[0]
#                 # Save augmented image with a unique name
#                 augmented_image.save(os.path.join(destination_dir, img_name_without_ext + f'_aug{i}.jpg'), 'JPEG')

#         except Exception as e:
#             print(f"Error augmenting image {abs_path}: {e}")

# source_dir = "/content/drive/MyDrive/dataset/jpeg/"
# destination_dir = "/content/drive/MyDrive/dataset/merged_images"

# # target_count=0 meaning no Augmentation, There's just Data-Balance
# target_count = (len(full_labels) * 3) - len(full_labels)
# copy_images_with_unique_filenames(full_images, full_labels, source_dir, destination_dir, target_count)

"""#read

"""

# Check the number of images in each class folder after merging
zero_class_count = len(os.listdir("/content/drive/MyDrive/ Breastcancer_Project1/dataset/merged_images/0"))
one_class_count  = len(os.listdir("/content/drive/MyDrive/ Breastcancer_Project1/dataset/merged_images/1"))

print(f"Number of images in class 0: {zero_class_count}")
print(f"Number of images in class 1: {one_class_count}")

data_dir = '/content/drive/MyDrive/ Breastcancer_Project1/dataset/merged_images'  # Update with the dataset path

# Create a dataset for the entire data to use for split
full_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    labels='inferred',
    label_mode='categorical',
    image_size=(224, 224),
    seed=50,
    shuffle=True,
    batch_size=13
)

# Calculate the total number of samples
total_samples = tf.data.experimental.cardinality(full_dataset).numpy()

train_size = int(0.8 * total_samples)                 # 80% for training
val_size   = int(0.15 * total_samples)                # 15% for validation
test_size = total_samples - train_size - val_size     # Remaining for testing

full_dataset = full_dataset.shuffle(total_samples, seed=50, reshuffle_each_iteration=False)

# Create train, validation, and test datasets
train_dataset       = full_dataset.take(train_size)
validation_dataset  = full_dataset.skip(train_size).take(val_size)
test_dataset        = full_dataset.skip(train_size + val_size)

# Prefetch to improve performance
train_dataset      = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
test_dataset       = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

# Print the number of samples in each dataset
print(f"Train samples:      {train_size*13}")
print(f"Validation samples: {val_size*13}")
print(f"Test samples:       {test_size*13}")

"""#50"""

from tensorflow.keras.applications import ResNet50

# Model directory
model_directory = "/content/drive/MyDrive/ Breastcancer_Project1/working/save_model/"

os.makedirs(model_directory, exist_ok=True)


def try_model():
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze all layers initially
    for layer in base_model.layers:
        layer.trainable = False

    # Calculate the index to start unfreezing layers
    from_index = int(np.round((len(base_model.layers) - 1) * (1.0 - 50.0 / 100.0)))

    # Unfreeze layers from the calculated index onwards
    for layer in base_model.layers[from_index:]:
        layer.trainable = True

    # Add custom layers on top (Upper-Layers)
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(2, activation='softmax')(x)  # Assuming binary classification

    model = Model(inputs=base_model.input, outputs=predictions)

    # # Clear the base model from memory if needed (optional)
    # del model_dict, base_model, from_index, x, predictions;    gc.collect()
    return model

from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.optimizers import Adam


trymodel = try_model()




trymodel.compile(optimizer=Adam(learning_rate=1e-4),
                      loss='categorical_crossentropy',
                      metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])  # Compile the model
trymodel.summary()

history = trymodel.fit(
            train_dataset,
            validation_data=validation_dataset,
            batch_size=13,
            epochs=7
        )

trymodel.save(model_directory+"my_model_1.h5")

"""#60"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import load_model
import cv2

# Define the second model with adjusted hyperparameters
def try_model_v2():
    base_model_v2 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze all layers initially
    for layer in base_model_v2.layers:
        layer.trainable = False

    # Unfreeze 60% of layers instead of 50%
    from_index_v2 = int(np.round((len(base_model_v2.layers) - 1) * (1.0 - 60.0 / 100.0)))

    # Unfreeze layers from the calculated index onwards
    for layer in base_model_v2.layers[from_index_v2:]:
        layer.trainable = True

    # Add custom layers on top (Upper-Layers)
    x_v2 = base_model_v2.output
    x_v2 = GlobalAveragePooling2D()(x_v2)
    x_v2 = Dense(512, activation='relu')(x_v2)  # Reduced Dense layer size from 1024 to 512
    x_v2 = Dropout(0.3)(x_v2)  # Lowered dropout rate from 0.5 to 0.3
    predictions_v2 = Dense(2, activation='softmax')(x_v2)  # Assuming binary classification

    model_v2 = Model(inputs=base_model_v2.input, outputs=predictions_v2)

    return model_v2

# Create and compile the second model
trymodel_v2 = try_model_v2()


trymodel_v2.compile(optimizer=Adam(learning_rate=5e-5),  # Adjusted learning rate to 5e-5
                    loss='categorical_crossentropy',
                    metrics=['accuracy', Precision(name='precision_v2'), Recall(name='recall_v2')])

# Train the second model
history_v2 = trymodel_v2.fit(
            train_dataset,
            validation_data=validation_dataset,
            batch_size=13,
            epochs=7
        )
trymodel_v2.save(model_directory+"my_model_2.h5")
# Summarize the second model
trymodel_v2.summary()

"""#70"""

# Define the third model with different hyperparameters
def try_model_v3():
    base_model_v3 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze all layers initially
    for layer in base_model_v3.layers:
        layer.trainable = False

    # Unfreeze 70% of layers (more layers unfreezed compared to v1 and v2)
    from_index_v3 = int(np.round((len(base_model_v3.layers) - 1) * (1.0 - 70.0 / 100.0)))

    # Unfreeze layers from the calculated index onwards
    for layer in base_model_v3.layers[from_index_v3:]:
        layer.trainable = True

    # Add custom layers on top (Upper-Layers)
    x_v3 = base_model_v3.output
    x_v3 = GlobalAveragePooling2D()(x_v3)
    x_v3 = Dense(1024, activation='relu')(x_v3)  # Return Dense layer size to 1024
    x_v3 = Dropout(0.4)(x_v3)  # Moderate dropout rate (between v1 and v2)
    predictions_v3 = Dense(2, activation='softmax')(x_v3)  # Assuming binary classification

    model_v3 = Model(inputs=base_model_v3.input, outputs=predictions_v3)

    return model_v3

# Create and compile the third model
trymodel_v3 = try_model_v3()


trymodel_v3.compile(optimizer=RMSprop(learning_rate=1e-4),  # Change optimizer to RMSprop and learning rate back to 1e-4
                    loss='categorical_crossentropy',
                    metrics=['accuracy', Precision(name='precision_v3'), Recall(name='recall_v3')])

# Train the third model
history_v3 = trymodel_v3.fit(
            train_dataset,
            validation_data=validation_dataset,
            batch_size=8,
            epochs=7
        )

trymodel_v3.save(model_directory+"my_model_3.h5")

# Summarize the third model
trymodel_v3.summary()

"""#plot"""



import matplotlib.pyplot as plt

model_name_1 = "ResNet50 with 50 percent layers"
model_name_2 = "ResNet50 with 60 percent layer"
model_name_3 = "ResNet50 with 70 percent layer"
# Plot accuracy comparison
plt.figure(figsize=(12, 8))


# Accuracy
plt.subplot(2, 2, 1)
plt.plot(history.history['accuracy'], label=model_name_1)
plt.plot(history_v2.history['accuracy'], label=model_name_2)
plt.plot(history_v3.history['accuracy'], label=model_name_3)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy')
plt.legend()

# Validation Accuracy
plt.subplot(2, 2, 2)
plt.plot(history.history['val_accuracy'], label=f"{model_name_1} Accuracy")
plt.plot(history_v2.history['val_accuracy'], label=f"{model_name_2} Accuracy")
plt.plot(history_v3.history['val_accuracy'], label=f"{model_name_3} Accuracy")
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Validation Accuracy')
plt.legend()

# Loss
plt.subplot(2, 2, 3)
plt.plot(history.history['loss'], label=f"{model_name_1} Loss")
plt.plot(history_v2.history['loss'], label=f"{model_name_2} Loss")
plt.plot(history_v3.history['loss'], label=f"{model_name_3} Loss")
plt.title('Training Loss')
plt.legend()

# Validation Loss
plt.subplot(2, 2, 4)
plt.plot(history.history['val_loss'], label=f"{model_name_1} Loss")
plt.plot(history_v2.history['val_loss'], label=f"{model_name_2} Loss")
plt.plot(history_v3.history['val_loss'], label=f"{model_name_3} Loss")
plt.title('Validation Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Plot Precision
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history['precision'], label=f"{model_name_1} Precision")
plt.plot(history_v2.history['precision_v2'], label=f"{model_name_2} Precision")
plt.plot(history_v3.history['precision_v3'], label=f"{model_name_3} Precision")
plt.xlabel('Epochs')
plt.ylabel('Precision')
plt.title('Training Precision')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['val_precision'], label=f"{model_name_1} Precision")
plt.plot(history_v2.history['val_precision_v2'], label=f"{model_name_2} Precision")
plt.plot(history_v3.history['val_precision_v3'], label=f"{model_name_3} Precision")
plt.xlabel('Epochs')
plt.ylabel('Precision')
plt.title('Validation Precision')
plt.legend()

plt.tight_layout()
plt.show()

# Plot Recall
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history['recall'], label=f"{model_name_1} Recall")
plt.plot(history_v2.history['recall_v2'], label=f"{model_name_2} Recall")
plt.plot(history_v3.history['recall_v3'], label=f"{model_name_3} Recall")
plt.xlabel('Epochs')  # Label for the X-axis
plt.ylabel('Recall')
plt.title('Training Recall')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['val_recall'], label=f"{model_name_1} Recall")
plt.plot(history_v2.history['val_recall_v2'], label=f"{model_name_2} Recall")
plt.plot(history_v3.history['val_recall_v3'], label=f"{model_name_3} Recall")
plt.xlabel('Epochs')  # Label for the X-axis
plt.ylabel('Recall')
plt.title('Validation Recall')
plt.legend()

plt.tight_layout()
plt.show()

#  Extract metrics for each model's history
metrics_data = {
    'Model': [],
    'Epoch': [],
    'Training Accuracy': [],
    'Validation Accuracy': [],
    'Training Loss': [],
    'Validation Loss': []
}

# Model 1 (history)
for epoch in range(len(history.history['accuracy'])):
    metrics_data['Model'].append(model_name_1)
    metrics_data['Epoch'].append(epoch + 1)
    metrics_data['Training Accuracy'].append(history.history['accuracy'][epoch])
    metrics_data['Validation Accuracy'].append(history.history['val_accuracy'][epoch])
    metrics_data['Training Loss'].append(history.history['loss'][epoch])
    metrics_data['Validation Loss'].append(history.history['val_loss'][epoch])

# Model 2 (history_v2)
for epoch in range(len(history_v2.history['accuracy'])):
    metrics_data['Model'].append(model_name_2)
    metrics_data['Epoch'].append(epoch + 1)
    metrics_data['Training Accuracy'].append(history_v2.history['accuracy'][epoch])
    metrics_data['Validation Accuracy'].append(history_v2.history['val_accuracy'][epoch])
    metrics_data['Training Loss'].append(history_v2.history['loss'][epoch])
    metrics_data['Validation Loss'].append(history_v2.history['val_loss'][epoch])

# Model 3 (history_v3)
for epoch in range(len(history_v3.history['accuracy'])):
    metrics_data['Model'].append(model_name_3)
    metrics_data['Epoch'].append(epoch + 1)
    metrics_data['Training Accuracy'].append(history_v3.history['accuracy'][epoch])
    metrics_data['Validation Accuracy'].append(history_v3.history['val_accuracy'][epoch])
    metrics_data['Training Loss'].append(history_v3.history['loss'][epoch])
    metrics_data['Validation Loss'].append(history_v3.history['val_loss'][epoch])


# Create a DataFrame from the metrics data
metrics_df = pd.DataFrame(metrics_data)

# Display the metrics table
print(metrics_df)

# Save the metrics table to a CSV file
metrics_df.to_csv('/content/drive/MyDrive/ Breastcancer_Project1/working/model_metrics.csv', index=False)

# Grad-CAM function
def grad_cam(model, image_array, last_conv_layer_name, class_index=None):
    grad_model = Model(inputs=model.input, outputs=[model.get_layer(last_conv_layer_name).output, model.output])

    # Compute gradients
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(image_array)
        if class_index is None:
            class_index = np.argmax(predictions[0])  # Default to top predicted class
        class_output = predictions[:, class_index]

    grads = tape.gradient(class_output, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_mean(conv_outputs * pooled_grads, axis=-1)  # Generate heatmap
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)  # Normalize heatmap to [0, 1]
    return heatmap

# Function to display Grad-CAM
def display_grad_cam(image, heatmap, alpha=0.4):
    # Remove batch dimension for the original image
    img = tf.squeeze(image, axis=0).numpy()  # Remove batch dimension (224, 224, 3)
    img = img.astype(np.uint8)  # Ensure the image is in the correct dtype

    # Resize heatmap to match the image dimensions
    heatmap_resized = tf.image.resize(heatmap[..., tf.newaxis], [img.shape[0], img.shape[1]])
    heatmap_resized = tf.squeeze(heatmap_resized, axis=-1).numpy()  # Remove extra channel

    """
    # Overlay the heatmap on the original image
    plt.imshow(img)
    plt.imshow(heatmap_resized, cmap='jet', alpha=alpha)
    plt.axis('off')
    plt.show()
    """

    # Normalize heatmap to range [0, 255] for blending
    heatmap_resized = np.uint8(255 * heatmap_resized)

    # Convert heatmap to a color map
    heatmap_colored = plt.cm.jet(heatmap_resized)[:, :, :3]  # Use the Jet colormap
    heatmap_colored = (heatmap_colored * 255).astype(np.uint8)  # Rescale to [0, 255]

    # Overlay the heatmap on the image
    overlay = cv2.addWeighted(img, 1 - alpha, heatmap_colored, alpha, 0)

    # Create a figure with two subplots
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    # Original image
    axes[0].imshow(img)
    axes[0].set_title("Original Image")
    axes[0].axis("off")

    # Grad-CAM Overlay
    axes[1].imshow(overlay)
    axes[1].set_title("Grad-CAM Overlay")
    axes[1].axis("off")

    plt.tight_layout()
    plt.show()

# Load your trained model
model  = load_model('/content/drive/MyDrive/ Breastcancer_Project1/working/save_model/my_model_1.h5')

last_conv_layer_name = "conv5_block3_out"  # Replace with your model's last conv layer

# Prepare your dataset (_PrefetchDataset)
dataset = tf.keras.utils.image_dataset_from_directory(
    "/content/drive/MyDrive/ Breastcancer_Project1/dataset/merged_images/1/",  # Directory of your test images
    label_mode=None,  # No labels required for Grad-CAM
    image_size=(224, 224),  # Resize to match the model input size
    batch_size=13  # Batch size
).map(lambda x: preprocess_input(x))  # Normalize inputs for the model

num_batches = 10

# Process each batch in the dataset
for batch in  dataset.take(num_batches):  # Take the first batch or loop over all batches
    for image in batch:  # Iterate through images in the batch
        image = tf.expand_dims(image, axis=0)  # Add batch dimension for the model
        print(f"Processing image with shape: {image.shape}")  # Debug shape

        # Generate Grad-CAM heatmap
        heatmap = grad_cam(model, image, last_conv_layer_name)


        # Display Grad-CAM result
        display_grad_cam(image, heatmap)

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import load_model
import cv2
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Grad-CAM function
def grad_cam(model, image_array, last_conv_layer_name, class_index=None):
    grad_model = Model(inputs=model.input, outputs=[model.get_layer(last_conv_layer_name).output, model.output])

    # Compute gradients
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(image_array)
        if class_index is None:
            class_index = np.argmax(predictions[0])  # Default to top predicted class
        class_output = predictions[:, class_index]

    grads = tape.gradient(class_output, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_mean(conv_outputs * pooled_grads, axis=-1)  # Generate heatmap
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)  # Normalize heatmap to [0, 1]
    return heatmap

# Function to display Grad-CAM
def display_grad_cam(image, heatmap, alpha=0.4):
    # Original image without preprocessing
    img_original = tf.squeeze(image, axis=0).numpy()
    img_original = img_original.astype(np.uint8)

    # Remove batch dimension for the processed image
    img_processed = tf.squeeze(image, axis=0).numpy()
    img_processed = (img_processed - np.min(img_processed)) / (np.max(img_processed) - np.min(img_processed)) * 255
    img_processed = img_processed.astype(np.uint8)

    # Resize heatmap to match the image dimensions
    heatmap_resized = tf.image.resize(heatmap[..., tf.newaxis], [img_original.shape[0], img_original.shape[1]])
    heatmap_resized = tf.squeeze(heatmap_resized, axis=-1).numpy()

    # Normalize heatmap to range [0, 255] for blending
    heatmap_resized = np.uint8(255 * heatmap_resized)

    # Convert heatmap to a color map
    heatmap_colored = plt.cm.jet(heatmap_resized)[:, :, :3]
    heatmap_colored = (heatmap_colored * 255).astype(np.uint8)

    # Overlay the heatmap on the image
    overlay = cv2.addWeighted(img_original, 1 - alpha, heatmap_colored, alpha, 0)

    # Create a figure with three subplots
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # Original image
    axes[0].imshow(img_original)
    axes[0].set_title("Original Image")
    axes[0].axis("off")

    # Preprocessed image
    axes[1].imshow(img_processed)
    axes[1].set_title("Preprocessed Image")
    axes[1].axis("off")

    # Grad-CAM Overlay
    axes[2].imshow(overlay)
    axes[2].set_title("Grad-CAM Overlay")
    axes[2].axis("off")

    plt.tight_layout()
    plt.show()

# Load your trained model
model = load_model('/content/drive/MyDrive/ Breastcancer_Project1/working/save_model/my_model_3.h5')
last_conv_layer_name = "conv5_block3_out"  # Replace with your model's last conv layer

# Function to process a single image
def process_single_image(image_path):
    # Load image
    image = load_img(image_path, target_size=(224, 224))  # Load image and resize
    original_image = img_to_array(image)  # Convert to array
    processed_image = preprocess_input(np.expand_dims(original_image, axis=0))  # Preprocess for the model

    # Generate Grad-CAM heatmap
    heatmap = grad_cam(model, processed_image, last_conv_layer_name)

    # Display Grad-CAM with both original and processed images
    display_grad_cam(np.expand_dims(original_image, axis=0), heatmap)

# Example: Process a specific image
image_path = "/content/drive/MyDrive/ Breastcancer_Project1/dataset/merged_images/1/00bd1d46a2074da1833107966e979231_1-020_aug1786.jpg"
process_single_image(image_path)

"""#final"""

# # true_classes = np.concatenate([y.numpy() for x, y in test_dataset], axis=0)
# # true_classes = np.argmax(true_classes, axis=1)

# import numpy as np

# true_classes = []

# for _, labels in test_dataset:
#     true_classes.append(labels.numpy())

# true_classes = np.concatenate(true_classes, axis=0)
# true_classes= np.argmax(true_classes,-1)
# print("All labels in the test dataset:")
# print(true_classes)

test_predictions = trymodel.predict(test_dataset)
predicted_classes = np.argmax(test_predictions, axis=1)

predicted_classes

report = classification_report(true_classes, predicted_classes, target_names=['Class 0', 'Class 1'])
print(report)

conf_matrix = confusion_matrix(true_classes, predicted_classes)

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels= ['Benign', 'Malignant'])
disp.plot(cmap=plt.cm.Blues)
plt.show()

positive_scores = test_predictions[:, 1]

fpr, tpr, thresholds = roc_curve(true_classes, positive_scores, pos_label=1)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix
accuracy_score(true_classes, predicted_classes),precision_score(true_classes, predicted_classes),recall_score(true_classes, predicted_classes),f1_score(true_classes, predicted_classes)

test_predictions = trymodel_v2.predict(test_dataset)
predicted_classes = np.argmax(test_predictions, axis=1)

report = classification_report(true_classes, predicted_classes, target_names=['Class 0', 'Class 1'])
print(report)

conf_matrix = confusion_matrix(true_classes, predicted_classes)

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels= ['Benign', 'Malignant'])
disp.plot(cmap=plt.cm.Blues)
plt.show()

positive_scores = test_predictions[:, 1]

fpr, tpr, thresholds = roc_curve(true_classes, positive_scores, pos_label=1)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix
accuracy_score(true_classes, predicted_classes),precision_score(true_classes, predicted_classes),recall_score(true_classes, predicted_classes),f1_score(true_classes, predicted_classes)

trymodel_v3 = load_model("/content/drive/MyDrive/ Breastcancer_Project1/working/save_model/my_model_3.h5")

test_predictions = trymodel_v3.predict(test_dataset)
predicted_classes = np.argmax(test_predictions, axis=1)

report = classification_report(true_classes, predicted_classes, target_names=['Class 0', 'Class 1'])
print(report)

conf_matrix = confusion_matrix(true_classes, predicted_classes)

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels= ['Benign', 'Malignant'])
disp.plot(cmap=plt.cm.Blues)
plt.show()


positive_scores = test_predictions[:, 1]

fpr, tpr, thresholds = roc_curve(true_classes, positive_scores, pos_label=1)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix
accuracy_score(true_classes, predicted_classes),precision_score(true_classes, predicted_classes),recall_score(true_classes, predicted_classes),f1_score(true_classes, predicted_classes)